{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = poppler.load_from_file(\"/data/Basic Rules (2014).pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.infos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc.create_page(7)\n",
    "page.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = page.text_list(page.TextListOption.text_list_include_font)\n",
    "for b in boxes:\n",
    "    print(b.text, b.get_font_name(), b.get_font_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    (p, i, b.text, b.get_font_name(), b.get_font_size())\n",
    "      for p in range(doc.pages)\n",
    "      for i, b in enumerate(doc.create_page(p).text_list(page.TextListOption.text_list_include_font))\n",
    "]\n",
    "df = pd.DataFrame(data, columns=[\"page\", \"word_in_page\", \"text\", \"font\", \"size\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"size > 20 and size < 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_headers = df.query(\"size > 30 and size < 35\")\n",
    "section_headers = df.query(\"size > 20 and size < 30\")\n",
    "section_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"size > 15 and size < 20\").groupby(\"page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_headers.groupby(\"page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_starts = section_headers.groupby(\"page\")[[\"page\", \"word_in_page\"]].transform(lambda x: min(x)).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_headers.groupby(\"page\")[\"text\"].transform(lambda x: \" \".join(x)).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pg, fonts in doc.create_font_iterator():\n",
    "    print(pg, [f.name for f in fonts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_starts = chapter_headers.groupby(\"page\")[[\"page\", \"word_in_page\"]].transform(lambda x: min(x)).drop_duplicates()\n",
    "chapter_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_heading = []\n",
    "section_heading = []\n",
    "current_doc = []\n",
    "\n",
    "in_chapter_heading = False\n",
    "in_section_heading = False\n",
    "last_font_size = 0\n",
    "\n",
    "docs = {}\n",
    "def stringify(thing):\n",
    "    return \" \".join(thing)\n",
    "\n",
    "for p in range(doc.pages):\n",
    "    page = doc.create_page(p)\n",
    "    for b in page.text_list(page.TextListOption.text_list_include_font):\n",
    "        font_size = b.get_font_size()\n",
    "\n",
    "        if font_size < last_font_size:\n",
    "            current_doc.append(\"\\n--------\\n\")\n",
    "\n",
    "        if font_size < 20:\n",
    "            if font_size > last_font_size:\n",
    "                current_doc.append(\"\\n\")\n",
    "            current_doc.append(b.text)\n",
    "\n",
    "        if font_size > last_font_size:\n",
    "            if font_size > 20:\n",
    "                # end of section\n",
    "                docs[f\"{stringify(chapter_heading)}{(' - ' + stringify(section_heading)) if section_heading else ''}\"] = f\"{stringify(chapter_heading)}\\n\\n{stringify(section_heading)}\\n{stringify(current_doc)}\"\n",
    "                current_doc = []\n",
    "                section_heading = []\n",
    "                if font_size > 30:\n",
    "                    # end of chapter\n",
    "                    chapter_heading = []\n",
    "\n",
    "        if font_size > 30 and font_size < 35:\n",
    "            chapter_heading.append(b.text)\n",
    "\n",
    "        if font_size > 20 and font_size < 30:\n",
    "            section_heading.append(b.text)\n",
    "\n",
    "        last_font_size = font_size\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.elastic import elastic_request\n",
    "import requests\n",
    "test = elastic_request(method=requests.post, url=\"_ingest/pipeline/clean_and_embed/_simulate\", data={\"docs\":[{\"_source\": {\"content\": docs[\"Preface\"]}}]})\n",
    "test.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_to_ingest = []\n",
    "\n",
    "for cursor in range(len(chapter_starts)):\n",
    "    start = chapter_starts.iloc[cursor]\n",
    "    print(df.query(f\"page == {start.page} and word_in_page >= {start.word_in_page}\")[\"text\"].values[0])\n",
    "    qry = f\"page >= {start.page} and word_in_page > {start.word_in_page}\"\n",
    "    if cursor+1 < len(chapter_starts):\n",
    "        end = chapter_starts.iloc[cursor+1]\n",
    "        qry += f\" and page <= {end.word_in_page} and word_in_page < {end.word_in_page}\"\n",
    "\n",
    "    sections_in_chapter = section_starts.query(qry)\n",
    "    if sections_in_chapter.empty:\n",
    "        docs_to_ingest.append(df.query(qry)[\"text\"].transform(lambda x: \" \".join(x)).values)\n",
    "    for cursor2 in range(len(sections_in_chapter)):\n",
    "        pass   \n",
    "\n",
    "\n",
    "# each section (defined from start word of a header to start word of the next header)\n",
    "#for cursor in range(len(section_starts)):\n",
    "#    start = section_starts.iloc[cursor]\n",
    "    #print(df.query(f\"page == {start.page} and word_in_page == {start.word_in_page}\")[\"text\"].values[0])\n",
    "#    if cursor+1 < len(section_starts):\n",
    "#        end = section_starts.iloc[cursor+1]\n",
    "    #    print(cursor, start.page, start.word_in_page, '-->', end.page, end.word_in_page)\n",
    "    #else:\n",
    "    #    print(cursor, start.page, start.word_in_page, '-->', \"END\")\n",
    "    \n",
    "    # get contents of section\n",
    "    # prepend header for chapter the section is in\n",
    "    \n",
    "# for each section header in the chapter (we know because it appears on a page between chapter N and chapter N+1)\n",
    "# create a doc containing everything between the section header and the next section header\n",
    "docs_to_ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"finer\" in docs[\"Preface\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
